---
title: 流式计算·引子
date: 2017-08-31 22:53:53
tags: bigdata
categories: 流式
copyright: true
password: Mike         
abstract: 流式计算总结，案例分析.
message: 请输入密码.
---

## 我用过的流式框架
目前常用流式计算包括storm/jstorm、flink、Apex、reef，额 spark-streaming，这货我一直觉得还是不要叫流式计算了吧，在对于时效性要求不是很苛刻的场景spark体系发挥巨大作用。
通常使用场景是需要n分钟内完成计算，这里`完成`是指从日志生成开始到经过上报、计算、落地，提供数据查询服务。还有一种极端情况就是所谓的秒级，这种场景极其特殊，一般不建议使用。

## 一个具体的场景·监控
大家对监控肯定不陌生，是个码农都能说出点关于监控的事情。
我宝每天交易量巨大，线上业务繁多，那么作为数据同学，日志量什么情况，大家都懂。
- 怎么计算？
- 怎么方便计算？
- 怎么恢复计算结果？
- 怎么在有限资源下计算？
- 怎么在大促期间抉择计算？

### 怎么计算
主要是考虑监控的时效性，选择流式框架来支持。对于支付系统来说，1分钟发现问题和10分钟发现问题虽然感觉10分钟也不长，但是如果资损了呢？如果用户不能扫码了呢？如果活动中断了呢？快速止血是码农必须具备的能力。要不怎么摔锅呢？


### 怎么方便计算
做过平台的同学都有感触，选用一个框架，并且把它研究透、打磨精光只是时间问题。比如storm，研究完之后，基于它部署一套流式计算平台就不是一件很困难的事情，但是如果计算任务每天都在快速增长，怎么提供开发效率？怎么降低维护成本？
这就需要平台化能力，我们通过会想到把storm的编程api抽象成配置化，计算任务基于配置完成，平台吃掉翻译配置的苦力活。
一般配置化要考虑几点：
- 日志切分能力。具备配置化支持日志切分提取能力。
- 日志聚合能力。切分后的字段，具备配置化自定义计算规则。
- 切分和聚合的关系。通常1:N
- 聚合和结果的关系。通常聚合id和聚合结果id有关系。
- 元数据管理。根据切分能知道所有聚合。根据聚合能知道所有key。
- 高阶能力。虚拟化切分、聚合能力。跨日志、跨集群的计算相关性能力。


### 怎么恢复计算结果
数据同学都会头痛容灾问题。容灾不是平台故障恢复就完事了，状态数据怎么恢复，锅怎么摔。
这是一个很复杂的话题。但是简单做法就是主备两套，力保核心。


### 怎么在有限资源下计算
你会发现随着时间推移，你的平台支撑的业务越来越多，想想三五年后会是什么样。
假如 1000个切分、10000个聚合，怎么分配资源，怎么降低运维。
这时候需要 资源治理。
这是个什么鬼？
首先，我们需要反问一句，三五年前的计算任务你还在用吗？再短点，一个月前的任务你还在用吗？很正常，一个运营活动发起后一周左右结束了，对应的计算任务也应该下线，但是如果没有对资源做管控，计算任务提交后，谁有知道那个任务什么时候该下线呢？
怎么治理？做血缘关系、生命周期管理、资源成本管理。

### 怎么在大促期间抉择计算？
大促期间力保核心，那么日志可能被降级。尼玛，日志都不采集了，你计算毛线？但是双11的实时大屏，你让马爸爸看白板吗？
怎么解？
假如 1000个切分、10000个聚合。那么其中最核心的业务有多少？初次之外的日志全部降级，力保核心不降级。
为了方便，通过指标的访问情况能知道其热度，另外借助血缘关系能感知是否核心，从多个维度实现自动核心归纳，实现动态核心运维。同时支持人工干预。

## 总结
扯了这么多，其实就三个字：元数据。
实现一个平台容易，但让这个平台运维简单很难。做好元数据，才是解决的最佳途径。
